%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{flairs}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{setspace}
\frenchspacing
\usepackage{verbatim}

\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\newcommand{\mytilde}{\raisebox{0.4ex}{\texttildelow}}
%----Making things more compact
\newcommand{\smalltt}[1]{{\small \tt #1}}
\newenvironment{packed_itemize}{
\vspace*{-0.2em}
\begin{itemize}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{itemize}}
\newenvironment{packed_enumerate}{
\vspace*{-0.2em}
\begin{enumerate}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{enumerate}}
\renewcommand{\textfraction}{0.07}
\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.9}
\renewcommand{\floatpagefraction}{0.66}
\setlength{\floatsep}{2.0pt plus 2.0pt minus 2.0pt}
\setlength{\textfloatsep}{10.0pt plus 2.0pt minus 0.0pt}

% \pdfinfo{
% /Title (ShZZaM: An LLM+ATP Natural Language to Logic Translator)
% /Author (Geoff Sutcliffe, Danial Haroon)}
% \setcounter{secnumdepth}{2}  
% \begin{document}
% \title{ShZZaM: An LLM+ATP Natural Language to Logic Translator}
% \author{Geoff Sutcliffe, Danial Haroon\\
% University of Miami\\
% Coral Gables, USA
% }
\pdfinfo{
/Title (ShZZaM: An LLM+ATP Natural Language to Logic Translator)
/Author (First1 Last1, First2 Last2)}
\setcounter{secnumdepth}{2}  
\begin{document}
\title{ShZZaM: An LLM+ATP Natural Language to Logic Translator}
\author{First1 Last1, First2 Last2\\
Affiliation\\
City, Country
}
\maketitle
\begin{abstract}
\begin{quote}
This paper describes the ShZZaM tool that uses Large Language Models (LLMs) and Automated
Theorem Proving (ATP) tools to translate natural language to typed first-order logic in
the TFF syntax of the TPTP World.
\end{quote}
\end{abstract}
%--------------------------------------------------------------------------------------------------
Large Language Models (LLMs)~\cite{PR+25} have shown themselves to be useful in a broad range
of applications~\cite{MK+25}.
However, it is well known that LLMs make mistakes~\cite{HY+25}, and this is acknowledged on 
LLMs' web interfaces, e.g., ChatGPT admits "ChatGPT can make mistakes. Check important info".
In the face of such unreliability, the results from LLMs in mission-critical applications require
verification.
One approach is to translate the LLM input and output to a logical form that can be checked
using Automated Theorem Proving (ATP) tools, e.g.,~\cite{YS+25,CL+25}.\footnote{%
For a more comprehensive survey, just ask your favourite LLM to ``show me some research on how LLMs 
make mistakes, and the need for symbolic checking of LLM output''.}
A key step in this verification pipeline is the faithful translation of the natural language to
an appropriate logical form.
This task is difficult due to the ambiguous nature of natural language statements, especially
informally expressed statements.
Work in this area includes LINC~\cite{OG+23}, FOLIO~\cite{HS+24}, and LINA~\cite{LL+24-arXiv}.
This paper makes another contribution in this area, taking a new interactive approach to the
translation process, zigzagging (hence the 'ZZ' in the tool name) between natural language and 
logic until convergence is achieved.
A key feature of ShZZaM is its use of LLMs and Automated Theorem Proving (ATP) tools, which
complement each other in the translation steps.

Figure~\ref{Process} shows the overall process implemented of ShZZaM.
Starting with the natural language, a combination of LLMs and ATP tools make a first translation
(step 1 - a ``Zig'') to the typed first-order logic in the TFF syntax~\cite{SS+12,BP13-TFF1} of 
the TPTP World~\cite{Sut24}.
An LLM is then used to translate the logic back to natural language (step 2 - a ``Zag'').
An LLM is then used to judge (step 3) whether or not the new and previous natural language 
statements have the same meaning.
If they are very dissimilar - below the ``acceptance threshold'' - the Zig step is rejected, and
is repeated.
If they are adequately similar - above the ``convergence threshold'', the logic inbetween them 
is accepted as the translation.
If the similarity lies between the acceptance and convergence thresholds then another zigzag is
performed. 
This zizagging continues until the natural language pairs converge to the required level of
similarity (or a limit is reached).
ANOTHER LOOP HERE.
Upon convergence the logic is sent to an ATP system via the SystemOnTPTP 
service~\cite{Sut00-CADE-17}, either a model finder if there are only axioms in the logic, or a
theorem prover if there is also a conjecture.
The results from the ATP system is reported in the SZS format~\cite{Sut08-KEAPPA}.

\begin{figure*}[bt]
\centering
\includegraphics[width=\textwidth]{Process.pdf}
\caption{ShZZaM process}
\label{Process}
\end{figure*}

Step 1, the translation from natural language to TFF logic, is an iterative one involving LLMs
and ATP tools.
Figure~\ref{Zig} shows the details.
An LLM is used to translate from natural language to logic.
The translation is successively checked for syntax errors, and if successful for type errors
(recall the logic is {\em typed} first-order logic).
If an error occurs in either check the error message is captured, and passed back into the LLM
for another attempt.
Note that after the logic passes the syntax and type checks, there is another outer level of
looping based on the similarity of the previous and new natural language, as explained above.

\begin{figure}[bt]
\centering
\includegraphics[width=\columnwidth]{Zig.pdf}
\caption{Translation from natural language to TFF logic}
\label{Zig}
\end{figure}

The LLM translation from natural language to logic and back again works because the LLM has
been exposed to enough natural language and enough TPTP format TFF logic.
The former is simply the results of scraping the world's web sites, etc.
The latter might be surprising, as TFF is comnparatively speaking a small fragment of the
data used to train the LLM.
Evidently there are adequate corpora that use TFF that are exposed on the web, e.g., the
TPTP problem library~\cite{Sut17}, exports from the Isabelle Archive of Formal 
Proofs~\cite{BH+15}, exports of the Mizar Mathematical Library~\cite{Urb03}, etc.

ShZZaM is implemented in Python.~\footnote{%
Available, with test files, from \smalltt{https://github.com/GeoffsPapers/ShZZaM}.}
ShZZaM has parameters that allow the selection of LLMs (default OpenAI's {\tt gpt-5-chat-latest})
and ATP systems (default Vampire~\cite{BB+25}), setting the acceptance, convergence, and
sequence thresholds (defaults 0.74, 0.94, 0.94), impose limits on the numbers of zigzags in a 
sequence (default 10), sequences (default 3), and failures in a Zig (default 10).

This paper describes the derivation and interpretation viewers in the TPTP World: 
the Interactive Derivation Viewer (IDV), the Interactive Tableau Viewer (ITV), the Interactive 
Interpretation Viewer (IIV), and the Interactive Kripke Viewer (IKV).
Users and developers of ATP systems are able to examine their ATP solutions in an interactive
graphical environment, providing insights into features of the solutions.
The viewers are freely accessible through SystemOnTPTP.

%--------------------------------------------------------------------------------------------------
\bibliographystyle{flairs}
\bibliography{Bibliography.bib}
%--------------------------------------------------------------------------------------------------
\end{document}
