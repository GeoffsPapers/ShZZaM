%File: formatting-instruction.tex
\documentclass[letterpaper]{article}
\usepackage{flairs}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\usepackage{graphicx}
\usepackage{setspace}
\frenchspacing
\usepackage{verbatim}

\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}

\newcommand{\mytilde}{\raisebox{0.4ex}{\texttildelow}}
%----Making things more compact
\newcommand{\smalltt}[1]{{\small \tt #1}}
\newenvironment{packed_itemize}{
\vspace*{-0.2em}
\begin{itemize}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{itemize}}
\newenvironment{packed_enumerate}{
\vspace*{-0.2em}
\begin{enumerate}
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}{\end{enumerate}}
\renewcommand{\textfraction}{0.07}
\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.9}
\renewcommand{\floatpagefraction}{0.66}
\setlength{\floatsep}{2.0pt plus 2.0pt minus 2.0pt}
\setlength{\textfloatsep}{10.0pt plus 2.0pt minus 0.0pt}

% \pdfinfo{
% /Title (ShZZaM: An LLM+ATP Natural Language to Logic Translator)
% /Author (Geoff Sutcliffe, Danial Haroon)}
% \setcounter{secnumdepth}{2}  
% \begin{document}
% \title{ShZZaM: An LLM+ATP Natural Language to Logic Translator}
% \author{Geoff Sutcliffe, Danial Haroon\\
% University of Miami\\
% Coral Gables, USA
% }
\pdfinfo{
/Title (ShZZaM: An LLM+ATP Natural Language to Logic Translator)
/Author (First1 Last1, First2 Last2)}
\setcounter{secnumdepth}{2}  
\begin{document}
\title{ShZZaM: An LLM+ATP Natural Language to Logic Translator}
\author{First1 Last1, First2 Last2\\
Affiliation\\
City, Country
}
\maketitle
\begin{abstract}
\begin{quote}
This paper describes ShZZaM, a tool that translates natural language to typed first-order logic, 
using Large Language Models (LLMs) and Automated Theorem Proving (ATP).
\end{quote}
\end{abstract}
%--------------------------------------------------------------------------------------------------
Large Language Models (LLMs)~\cite{PR+25} have shown themselves to be useful in a broad range
of applications~\cite{MK+25}.
However, it is well known that LLMs make mistakes~\cite{HY+25}, and this is acknowledged on 
LLMs' web interfaces, e.g., ChatGPT admits "ChatGPT can make mistakes. Check important info".
In the face of such unreliability, the results from LLMs in mission-critical applications require
verification.
One approach is to translate the LLM input and output to a logical form that can be checked
using Automated Theorem Proving (ATP) tools, e.g.,~\cite{YS+25,CL+25}.\footnote{%
For a more comprehensive survey, just ask your favourite LLM to ``show me some research on how LLMs 
make mistakes, and the need for symbolic checking of LLM output''.}
A key step in this verification pipeline is the faithful translation of the natural language to
an appropriate logical form.
This task is difficult due to the ambiguous nature of natural language statements, especially
informally expressed statements.
Work in this area includes LINC~\cite{OG+23}, FOLIO~\cite{HS+24}, and LINA~\cite{LL+24-arXiv}.
This paper makes another contribution, taking a new interactive approach to the translation
process, zigzagging between natural language and logic until convergence is achieved (hence the
'ZZ' in the tool name).
A key feature of ShZZaM is its use of LLMs and Automated Theorem Proving (ATP), which
complement each other in the translation steps.

Figure~\ref{Process} shows the overall process of ShZZaM.
Starting with the natural language, a combination of LLMs and ATP tools makes a first translation
(LLM-L+ATP - a ``Zig'') to the typed first-order logic in the TFF syntax~\cite{BP13-TFF1} of 
the TPTP World~\cite{Sut24}.
An LLM is then used to translate the logic back to natural language (LLM-NL - a ``Zag'').
An LLM is then used to judge the similarity in meaning of the new and previous natural language
statements (LLM-S).
If they are adequately similar - above a ``convergence threshold'', the logic in between them 
is accepted as the translation.
If not another zigzag is performed.
This zizagging continues until the natural language pairs converge to the required level of
similarity (or a limit is reached).
Upon convergence the logic is sent to an ATP system, either a theorem prover if there is a
conjecture, or a model finder if there are only axioms.
The results from the ATP system is reported in the SZS format~\cite{Sut08-KEAPPA}.
If the similarity between the final natural language and the original natural language
(which is computed in the zigzag step - see below) is above the ``zigzagging sequence threshold''
the translation is complete.
Otherwise another zigzagging sequence is performed (or a limit is reached).
This outermost zigzagging sequence loop ensures that the final natural language is adequately
similar in meaning to the original natural language.

\begin{figure*}[bt]
\centering
\includegraphics[width=\textwidth]{Process.pdf}
\caption{ShZZaM process}
\label{Process}
\end{figure*}

The translation from natural language to logic and back - one zigzag, is an iterative one involving
LLMs and ATP tools.
Figure~\ref{ZigZag} shows the details.
LLM-L is used to translate from natural language to logic.
The translation is successively checked using ATP tools for syntax errors and type errors (recall 
the logic is {\em typed} first-order logic).
If an error occurs in either check the error message is captured and passed back into the LLM-L 
for another attempt.
When a syntactically and type correct logic is created, LLM-NL translates the logic back to
the provisional natural language, and LLM-S is used to compare this to the original natural 
language.
If the similarity is above an ``acceptance threshold'' the provisional natural language becomes
the accepted result of the zigzag.
It is this accepted natural language that is compared to the previous natural language for
convergence, as explained above.
If the similarity is below the acceptance threshold then the provisional natural language is
rejected, and the error is passed back into the LLM-L for another attempt.
This check prevents the natural language straying too far in meaning from the original natural
language over multiple zigzags.

\begin{figure*}[bt]
\centering
\includegraphics[width=\textwidth]{ZigZag.pdf}
\caption{Details of one zigzag}
\label{ZigZag}
\end{figure*}

The LLM translation from natural language to logic and back again works because LLMs are
exposed to enough natural language and enough TPTP format TFF logic.
The former is the natural result of scraping the world's web sites, etc.
The latter might be surprising, as TFF is a comparatively small fragment of the data used to train
LLMs.
Evidently there are adequate corpora that use TFF that are exposed on the web, e.g., the
TPTP problem library~\cite{Sut17}, exports from the Isabelle Archive of Formal 
Proofs~\cite{BH+15}, exports of the Mizar Mathematical Library~\cite{Urb03}, etc.

ShZZaM is implemented in Python.
The LLMs available are OpenAI's \smalltt{gpt-5-chat-latest} and Google's 
\smalltt{gemini-2.5-flash}.
Access to ATP is provided via the TPTP World's SystemOnTPTP service~\cite{Sut00-CADE-17}.
ShZZaM has parameters that allow the selection of LLMs (default OpenAI) and ATP systems (default
Vampire~\cite{BB+25} for both theorem proving and model finding), setting the acceptance,
convergence, and zigzagging sequence thresholds (defaults 0.74, 0.94, 0.94), setting the maximal
numbers of failures in a Zig (default 10), zigzags in a sequence (default 10), and zigzagging
sequence repetitions (default 3).
ShZZaM is available, with test files and the results discussed below, from 
\smalltt{https://github.com/GeoffsPapers/ShZZaM}.
It can also be run in default mode in SystemB4TPTP, at 
\smalltt{https://tptp.org/cgi-bin/SystemB4TPTP}, by selecting ``English'' as the ``Input as in''
option.
An OpenAI API key has to be provided in an initial comment line, e.g.,
\begin{verbatim}
# OPENAI_API_KEY=the_user_api_key
ShZZaM is a nice translation tool.
\end{verbatim}
No tool needs to be selected -- just ``ProcessProblem''.

Initial testing has been done on 12 test texts from SUMO-based research~\cite{NP01,TP+25}.
There are four texts that are expected to produce axioms with a provable conjecture, three texts
that that are expected to produce axioms with an unprovable conjecture, and five contradictory
texts that are expected to produce unsatisfiable axioms.
An example of the first type is:
``If a country is a member of NATO, it will protect any member that is attacked. 
Sweden is a member of NATO. 
Germany is a member of NATO.
Russia attacked Germany.
Will Sweden protect Germany?''.
An example of the second type is:
``Terry possesses a Traditional Savings Account.
Terry withdrew from the Traditional Savings Account.
The bank penalized Terry.
Did the withdrawal cause a penalty?''.
An example of the third type is:
``The tornado damaged the house.
The tornado did not damage the house.''.
Testing used the default settings, plus additionally used the Google LLM for the language
translations.
Each test was run three times so that stochastic variations could be analysed, for a total of 
72 runs.
Of the 72 runs, 65 ended in convergence, 36 converged above the zigzagging sequence threshold,
26 required only one zigzagging sequence, 6 required two sequences, and 40 used all three
sequences.
The ATP system confirmed the logical status in 21 of the 24 theorem runs, 17 of the 18 non-theorem
runs, and 18 of the 30 unsatisfiable axiom set runs.
The OpenAI model produced the best results, with 32 of its 36 results confirmed by the ATP system,
while Google achieved 24 out of 36.
The stochastic variations are interesting:
Of the 24 sets of three test runs, 10 OpenAI sets and 7 Google sets were confirmed by the ATP
system in all three runs.
Manual inspection of the logic outputs showed that only 6 of the OpenAI sets and 1 of the Google
sets produced essentially the same logic in each of the three runs.
Thus repeatability is low.

% resulting in 158 runs
% (not the maximal 216, because some runs used less than the maximal three zigzagging repetitions).

Future work includes adding access to more LLMs, e.g., Anthropic's \smalltt{claude-sonnet-4-5},
testing over larger datasets, e.g., the FOLIO~\cite{HS+24} and ProofWriter~\cite{TDC21} datasets.
The main weakness of ShZZaM (and speculatively all other natural language to logic translators)
is its stochastic nature -- the logic produced typically varies between runs.
This is a matter for further and deeper research.

%--------------------------------------------------------------------------------------------------
\bibliographystyle{flairs}
\bibliography{Bibliography.bib}
%--------------------------------------------------------------------------------------------------
\end{document}
